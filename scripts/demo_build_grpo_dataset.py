#!/usr/bin/env python3
"""
Demo GRPO Dataset Builder

This demo version shows the complete GRPO dataset generation workflow
without requiring a valid OpenAI API key, using predefined mock responses.
"""

import json
import re
import time
import random
from pathlib import Path
from typing import Dict, List, Any, Tuple
from tqdm import tqdm

# Mock GRPO responses for demonstration
DEMO_GRPO_RESPONSES = {
    "–ß–∏–Ω–≥–∏—Å —Ö–∞–∞–Ω": {
        "chosen": "–ß–∏–Ω–≥–∏—Å —Ö–∞–∞–Ω (1162-1227) –±–æ–ª –ú–æ–Ω–≥–æ–ª—ã–Ω –∞–≥—É—É —Ö–∞–∞–Ω, –ò—Ö –ú–æ–Ω–≥–æ–ª –£–ª—Å—ã–≥ –±–∞–π–≥—É—É–ª–∞–≥—á —é–º. –¢—ç—Ä—ç—ç—Ä 1206 –æ–Ω–¥ –ú–æ–Ω–≥–æ–ª—ã–Ω –æ–≤–æ–≥ –∞–π–º–≥—É—É–¥—ã–≥ –Ω—ç–≥—Ç–≥—ç–∂, –¥—ç–ª—Ö–∏–π–Ω —Ç“Ø“Ø—Ö—ç–Ω –¥—ç—Ö —Ö–∞–º–≥–∏–π–Ω —Ç–æ–º —ç–∑—ç–Ω—Ç –≥“Ø—Ä–Ω–∏–π–≥ –±–∞–π–≥—É—É–ª—Å–∞–Ω. –ß–∏–Ω–≥–∏—Å —Ö–∞–∞–Ω—ã —É–¥–∏—Ä–¥–ª–∞–≥–∞ –¥–æ—Ä –ú–æ–Ω–≥–æ–ª—á—É—É–¥ –•—è—Ç–∞–¥, –•–æ—Ä–µ–∑–º, –û—Ä–æ—Å –∑—ç—Ä—ç–≥ –æ–ª–æ–Ω —É–ª—Å—ã–≥ –±–∞–π–ª–¥–∞–Ω –¥–∞–≥—É—É–ª–∂, –ú–æ–Ω–≥–æ–ª—ã–Ω —Å–æ—ë–ª, —Ö—É—É–ª—å —Ç–æ–≥—Ç–æ–æ–º–∂–∏–π–≥ –¥—ç–ª–≥—ç—Ä“Ø“Ø–ª—Å—ç–Ω.",
        "rejected": "–ß–∏–Ω–≥–∏—Å —Ö–∞–∞–Ω –±–æ–ª –ú–æ–Ω–≥–æ–ª—ã–Ω —Ö–∞–∞–Ω –±–∞–π—Å–∞–Ω. –¢—ç—Ä –º–∞—à —Ö“Ø—á–∏—Ä—Ö—ç–≥ –±–∞–π—Å–∞–Ω –±”©–≥”©”©–¥ –æ–ª–æ–Ω –≥–∞–∑–∞—Ä –±–∞–π–ª–¥—Å–∞–Ω."
    },
    "1921 –æ–Ω—ã —Ö—É–≤—å—Å–≥–∞–ª": {
        "chosen": "1921 –æ–Ω—ã –ú–æ–Ω–≥–æ–ª—ã–Ω –∞—Ä–¥—ã–Ω —Ö—É–≤—å—Å–≥–∞–ª –Ω—å –ú–æ–Ω–≥–æ–ª—ã–Ω —Ç“Ø“Ø—Ö—ç–Ω–¥ —á—É—Ö–∞–ª “Ø–π–ª —è–≤–¥–∞–ª –±–æ–ª—Å–æ–Ω. –≠–Ω—ç —Ö—É–≤—å—Å–≥–∞–ª–∞–∞—Ä –ú–æ–Ω–≥–æ–ª –£–ª—Å –ú–∞–Ω–∂ –ß–∏–Ω –≥“Ø—Ä–Ω–∏–π –∑–∞—Å–∞–≥–ª–∞–ª–∞–∞—Å –∞–Ω–≥–∏–∂–∏—Ä—á, —Å–æ—Ü–∏–∞–ª–∏—Å—Ç –∑–∞–º—ã–≥ —Å–æ–Ω–≥–æ—Å–æ–Ω. –°“Ø—Ö–±–∞–∞—Ç–∞—Ä, –ß–æ–π–±–∞–ª—Å–∞–Ω –∑—ç—Ä—ç–≥ —É–¥–∏—Ä–¥–∞–≥—á–¥—ã–Ω —É–¥–∏—Ä–¥–ª–∞–≥–∞ –¥–æ—Ä —Ö—É–≤—å—Å–≥–∞–ª –∞–º–∂–∏–ª—Ç—Ç–∞–π –±–æ–ª–∂, –ú–æ–Ω–≥–æ–ª—ã–Ω –ê—Ä–¥—ã–Ω –†–µ—Å–ø—É–±–ª–∏–∫ –±–∞–π–≥—É—É–ª–∞–≥–¥—Å–∞–Ω.",
        "rejected": "1921 –æ–Ω–¥ –ú–æ–Ω–≥–æ–ª–¥ —Ö—É–≤—å—Å–≥–∞–ª –±–æ–ª—Å–æ–Ω. –≠–Ω—ç –Ω—å —á—É—Ö–∞–ª “Ø–π–ª —è–≤–¥–∞–ª –±–∞–π—Å–∞–Ω."
    },
    "–ë–æ–≥–¥ —Ö–∞–∞–Ω—ã “Ø–µ": {
        "chosen": "–ë–æ–≥–¥ —Ö–∞–∞–Ω—ã “Ø–µ (1911-1924) –Ω—å –ú–æ–Ω–≥–æ–ª—ã–Ω —Ç—É—Å–≥–∞–∞—Ä —Ç–æ–≥—Ç–Ω–æ–ª—ã–Ω –∞–Ω—Ö–Ω—ã “Ø–µ –±–∞–π–≤. VIII –ë–æ–≥–¥ –ñ–∞–≤–∑–∞–Ω–¥–∞–º–±–∞ —Ö—É—Ç–∞–≥—Ç –ú–æ–Ω–≥–æ–ª—ã–Ω —Ö–∞–∞–Ω –±–æ–ª–∂, —Ç–µ–æ–∫—Ä–∞—Ç –∑–∞—Å–∞–≥–ª–∞–ª —Ç–æ–≥—Ç–æ–æ—Å–æ–Ω. –≠–Ω—ç “Ø–µ–¥ –ú–æ–Ω–≥–æ–ª –£–ª—Å –ú–∞–Ω–∂ –ß–∏–Ω –≥“Ø—Ä–Ω—ç—ç—Å —Ç—É—Å–≥–∞–∞—Ä —Ç–æ–≥—Ç–Ω–æ–∂, ”©”©—Ä–∏–π–Ω –≥—ç—Å—ç–Ω –∑–∞—Å–≥–∏–π–Ω –≥–∞–∑–∞—Ä, —Ü—ç—Ä—ç–≥ –±–∞–π–≥—É—É–ª—Å–∞–Ω –±–æ–ª–æ–≤—á –æ–ª–æ–Ω —É–ª—Å—ã–Ω —Ö“Ø–ª—ç—ç–Ω –∑”©–≤—à”©”©—Ä”©–ª –∞–≤–∞—Ö–∞–¥ –±—ç—Ä—Ö—à—ç—ç–ª—Ç—ç–π —Ç—É–ª–≥–∞—Ä—Å–∞–Ω.",
        "rejected": "–ë–æ–≥–¥ —Ö–∞–∞–Ω –ú–æ–Ω–≥–æ–ª—ã–Ω —Ö–∞–∞–Ω –±–∞–π—Å–∞–Ω. –¢—ç—Ä 1911-1924 –æ–Ω–¥ –∑–∞—Å–∞–≥–ª–∞–∂ –±–∞–π—Å–∞–Ω."
    },
    "–•“Ø–Ω–Ω“Ø —É–ª—Å": {
        "chosen": "–•“Ø–Ω–Ω“Ø —É–ª—Å (–ù–¢”® 209 - –ù–¢ 93) –Ω—å –ú–æ–Ω–≥–æ–ª—ã–Ω –Ω—É—Ç–∞–≥—Ç –±–∞–π–≥—É—É–ª–∞–≥–¥—Å–∞–Ω –∞–Ω—Ö–Ω—ã —Ç–æ–º –Ω“Ø“Ø–¥—ç–ª—á–¥–∏–π–Ω —É–ª—Å –±–∞–π–≤. –ú–æ–¥—É–Ω —à–∞–Ω—å—é–π–≥–∏–π–Ω —É–¥–∏—Ä–¥–ª–∞–≥–∞ –¥–æ—Ä –•“Ø–Ω–Ω“Ø —É–ª—Å —Ö“Ø—á–∏—Ä—Ö—ç–≥–∂–∏–∂, –•—è—Ç–∞–¥—ã–Ω –•–∞–Ω —É–ª—Å—Ç–∞–π —Ç—ç–Ω—Ü—ç—Ö“Ø–π—Ü —Ö“Ø—á–∏–Ω —á–∞–¥–∞–ª—Ç–∞–π –±–æ–ª—Å–æ–Ω. –•“Ø–Ω–Ω“Ø“Ø–¥ –Ω“Ø“Ø–¥—ç–ª—á–¥–∏–π–Ω —Å–æ—ë–ª, —Ü—ç—Ä–≥–∏–π–Ω —Ç–∞–∫—Ç–∏–∫, –¥–∏–ø–ª–æ–º–∞—Ç —Ö–∞—Ä–∏–ª—Ü–∞–∞–≥ —Ö”©–≥–∂“Ø“Ø–ª–∂, –¥–∞—Ä–∞–∞–≥–∏–π–Ω “Ø–µ–∏–π–Ω –ú–æ–Ω–≥–æ–ª—ã–Ω —É–ª—Å—É—É–¥–∞–¥ –∏—Ö—ç—ç—Ö—ç–Ω –Ω”©–ª”©”© “Ø–∑“Ø“Ø–ª—Å—ç–Ω.",
        "rejected": "–•“Ø–Ω–Ω“Ø —É–ª—Å –±–æ–ª —ç—Ä—Ç–Ω–∏–π –ú–æ–Ω–≥–æ–ª—ã–Ω —É–ª—Å –±–∞–π—Å–∞–Ω. –¢—ç–¥ –Ω“Ø“Ø–¥—ç–ª—á–∏–Ω –±–∞–π—Å–∞–Ω."
    },
    "–ê—Ä–¥—á–∏–ª—Å–∞–Ω —Ö—É–≤—å—Å–≥–∞–ª": {
        "chosen": "1990 –æ–Ω—ã –∞—Ä–¥—á–∏–ª—Å–∞–Ω —Ö—É–≤—å—Å–≥–∞–ª –Ω—å –ú–æ–Ω–≥–æ–ª –£–ª—Å—ã–≥ –Ω—ç–≥ –Ω–∞–º—ã–Ω —Å–æ—Ü–∏–∞–ª–∏—Å—Ç —Ç–æ–≥—Ç–æ–ª—Ü–æ–æ–Ω–æ–æ—Å –æ–ª–æ–Ω –Ω–∞–º—ã–Ω –∞—Ä–¥—á–∏–ª—Å–∞–Ω —Ç–æ–≥—Ç–æ–ª—Ü–æ–æ —Ä—É—É —Ç–∞–π–≤–∞–Ω –∑–∞–º–∞–∞—Ä —à–∏–ª–∂“Ø“Ø–ª—Å—ç–Ω —Ç“Ø“Ø—Ö—ç–Ω “Ø–π–ª —è–≤–¥–∞–ª —é–º. –≠–Ω—ç —Ö—É–≤—å—Å–≥–∞–ª–∞–∞—Ä –ú–ê–•–ù-—ã–Ω –º–æ–Ω–æ–ø–æ–ª—å –∑–∞—Å–∞–≥–ª–∞–ª –¥—É—É—Å—á, –æ–ª–æ–Ω –Ω–∞–º “Ø“Ø—Å—ç–∂, 1992 –æ–Ω–¥ —à–∏–Ω—ç “Æ–Ω–¥—Å—ç–Ω —Ö—É—É–ª—å –±–∞—Ç–ª–∞–≥–¥—Å–∞–Ω. –ú–æ–Ω–≥–æ–ª –£–ª—Å –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —ç–¥–∏–π–Ω –∑–∞—Å–∞–≥—Ç —à–∏–ª–∂–∏–∂, –∞—Ä–¥—á–∏–ª—Å–∞–Ω –∑–∞—Å–∞–≥–ª–∞–ª—ã–≥ —Ç–æ–≥—Ç–æ–æ—Å–æ–Ω.",
        "rejected": "1990 –æ–Ω–¥ –ú–æ–Ω–≥–æ–ª–¥ –∞—Ä–¥—á–∏–ª—Å–∞–Ω —Ö—É–≤—å—Å–≥–∞–ª –±–æ–ª—Å–æ–Ω. –≠–Ω—ç –Ω—å ”©”©—Ä—á–ª”©–ª—Ç –∞–≤—á–∏—Ä—Å–∞–Ω."
    }
}

class DemoGRPOBuilder:
    """Demo GRPO dataset builder with mock responses."""
    
    def __init__(self):
        """Initialize demo builder."""
        self.question_templates = [
            "{topic} —Ö—ç–∑—ç—ç –±–æ–ª—Å–æ–Ω –±—ç?",
            "{topic}-—ã–Ω “Ø–Ω–¥—Å—ç–Ω —à–∞–ª—Ç–≥–∞–∞–Ω —é—É –±–∞–π—Å–∞–Ω –±—ç?",
            "{topic}-—ã–Ω “Ø—Ä –¥“Ø–Ω –Ω—å —é—É –±–∞–π—Å–∞–Ω –±—ç?",
            "{topic} —è–∞–≥–∞–∞–¥ —á—É—Ö–∞–ª –±–∞–π—Å–∞–Ω –±—ç?",
            "{topic}-–¥ —Ö—ç–Ω –æ—Ä–æ–ª—Ü—Å–æ–Ω –±—ç?",
            "{topic}-—ã–Ω –∞—á —Ö–æ–ª–±–æ–≥–¥–æ–ª —é—É–Ω–¥ –æ—Ä—à–¥–æ–≥ –≤—ç?",
            "{topic} —Ö—ç—Ä—Ö—ç–Ω ”©—Ä–Ω”©—Å”©–Ω –±—ç?",
            "{topic}-—ã–Ω —Ç–∞–ª–∞–∞—Ä –¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —è—Ä–∏–Ω–∞ —É—É?",
            "{topic} –ú–æ–Ω–≥–æ–ª—ã–Ω —Ç“Ø“Ø—Ö—ç–Ω–¥ —è–º–∞—Ä –Ω”©–ª”©”© “Ø–∑“Ø“Ø–ª—Å—ç–Ω –±—ç?",
            "{topic}-—Ç–∞–π —Ö–æ–ª–±–æ–æ—Ç–æ–π –≥–æ–ª “Ø–π–ª —è–≤–¥–ª—É—É–¥ —é—É –≤—ç?"
        ]
    
    def extract_topics_from_content(self, content: str) -> List[str]:
        """Extract topics from content."""
        # Look for key historical terms
        topics = []
        
        # Check for known topics in demo responses
        for topic in DEMO_GRPO_RESPONSES.keys():
            if topic.lower() in content.lower():
                topics.append(topic)
        
        # Extract other potential topics
        topic_patterns = [
            r'(\d{4})\s*–æ–Ω—ã?\s+([^.!?]{10,50})',
            r'([–ê-–Ø”®“Æ][–∞-—è”©“Ø\s]{5,30}(?:—Ö—É–≤—å—Å–≥–∞–ª|–¥–∞–π–Ω|—Ö–∞–∞–Ω|—É–ª—Å))',
            r'([–ê-–Ø”®“Æ][–∞-—è”©“Ø\s]{5,30}(?:“Ø–µ|—Ü–∞–≥|–∑—É—É–Ω))'
        ]
        
        for pattern in topic_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                if isinstance(match, tuple):
                    topic = ' '.join(str(m) for m in match if m).strip()
                else:
                    topic = str(match).strip()
                
                topic = re.sub(r'\s+', ' ', topic)
                if 5 < len(topic) < 50:
                    topics.append(topic)
        
        return list(set(topics))[:5]  # Limit to 5 topics per content
    
    def generate_questions_for_topic(self, topic: str, count: int = 2) -> List[str]:
        """Generate questions for a topic."""
        questions = []
        templates = random.sample(self.question_templates, min(count, len(self.question_templates)))
        
        for template in templates:
            question = template.format(topic=topic)
            questions.append(question)
        
        return questions
    
    def generate_grpo_pair(self, question: str, context: str) -> Dict[str, str]:
        """Generate a mock GRPO pair."""
        # Simulate API delay
        time.sleep(0.3)
        
        # Find matching topic in demo responses
        for topic, responses in DEMO_GRPO_RESPONSES.items():
            if topic.lower() in question.lower() or topic.lower() in context.lower():
                return {
                    "prompt": question,
                    "chosen": responses["chosen"],
                    "rejected": responses["rejected"]
                }
        
        # Generate generic response if no match
        return {
            "prompt": question,
            "chosen": f"–≠–Ω—ç –∞—Å—É—É–ª—Ç—ã–Ω —Ö–∞—Ä–∏—É–ª—Ç –Ω—å –ú–æ–Ω–≥–æ–ª—ã–Ω —Ç“Ø“Ø—Ö–∏–π–Ω —á—É—Ö–∞–ª —Ö—ç—Å—ç–≥ —é–º. –î—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π –º—ç–¥—ç—ç–ª—ç–ª –∞–≤–∞—Ö—ã–Ω —Ç—É–ª–¥ —Ç“Ø“Ø—Ö–∏–π–Ω —ç—Ö —Å—É—Ä–≤–∞–ª–∂—É—É–¥—ã–≥ —Å—É–¥–ª–∞—Ö —Ö—ç—Ä—ç–≥—Ç—ç–π. –≠–Ω—ç “Ø–π–ª —è–≤–¥–∞–ª –ú–æ–Ω–≥–æ–ª—ã–Ω —Å–æ—ë–ª, —É–ª—Å —Ç”©—Ä–∏–π–Ω —Ö”©–≥–∂–∏–ª–¥ –∏—Ö—ç—ç—Ö—ç–Ω –Ω”©–ª”©”© “Ø–∑“Ø“Ø–ª—Å—ç–Ω –±–∞–π–¥–∞–≥.",
            "rejected": "–≠–Ω—ç —Ç–∞–ª–∞–∞—Ä —Ç–æ–¥–æ—Ä—Ö–æ–π –º—ç–¥—ç—ç–ª—ç–ª –±–∞–π—Ö–≥“Ø–π –±–∞–π–Ω–∞. –ú–∞–≥–∞–¥–≥“Ø–π —á—É—Ö–∞–ª –±–∞–π—Å–∞–Ω –±–∞–π—Ö."
        }
    
    def load_source_data(self, file_path: Path) -> List[Dict[str, Any]]:
        """Load source data from file."""
        records = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                if file_path.suffix == '.jsonl':
                    for line in f:
                        line = line.strip()
                        if line:
                            try:
                                record = json.loads(line)
                                records.append(record)
                            except json.JSONDecodeError:
                                continue
                else:
                    data = json.load(f)
                    if isinstance(data, list):
                        records.extend(data)
                    elif isinstance(data, dict):
                        records.append(data)
        
        except Exception as e:
            print(f"Error loading {file_path}: {e}")
        
        return records
    
    def build_demo_grpo_dataset(self, source_file: Path, output_file: Path, pairs_count: int = 10):
        """Build demo GRPO dataset."""
        print("üéØ DEMO: GRPO Dataset Generation")
        print("=" * 50)
        print(f"Source: {source_file}")
        print(f"Output: {output_file}")
        print(f"Target pairs: {pairs_count}")
        print()
        
        # Load source data
        print("üìÅ Loading source data...")
        records = self.load_source_data(source_file)
        print(f"Loaded {len(records)} records")
        
        # Generate questions
        print("‚ùì Generating questions from content...")
        question_pairs = []
        
        for record in records[:10]:  # Limit to first 10 records for demo
            content = ""
            for field in ['text', 'content', 'chosen']:
                if field in record and record[field]:
                    content = str(record[field])
                    break
            
            if len(content) < 100:
                continue
            
            topics = self.extract_topics_from_content(content)
            for topic in topics:
                questions = self.generate_questions_for_topic(topic, 1)
                for question in questions:
                    question_pairs.append((question, content))
        
        # Limit to requested count
        question_pairs = question_pairs[:pairs_count]
        print(f"Generated {len(question_pairs)} question-context pairs")
        print()
        
        # Generate GRPO pairs
        print("üîÑ Generating GRPO preference pairs...")
        grpo_pairs = []
        
        for question, context in tqdm(question_pairs, desc="Processing"):
            grpo_pair = self.generate_grpo_pair(question, context)
            grpo_pairs.append(grpo_pair)
            
            # Show example
            if len(grpo_pairs) <= 3:
                print(f"\\n‚úÖ Generated pair {len(grpo_pairs)}:")
                print(f"   Prompt: {grpo_pair['prompt']}")
                print(f"   Chosen: {grpo_pair['chosen'][:80]}...")
                print(f"   Rejected: {grpo_pair['rejected'][:60]}...")
        
        # Save results
        print(f"\\nüíæ Saving {len(grpo_pairs)} pairs to {output_file}")
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            for pair in grpo_pairs:
                json.dump(pair, f, ensure_ascii=False)
                f.write('\\n')
        
        # Generate statistics
        chosen_lengths = [len(pair['chosen'].split()) for pair in grpo_pairs]
        rejected_lengths = [len(pair['rejected'].split()) for pair in grpo_pairs]
        prompt_lengths = [len(pair['prompt'].split()) for pair in grpo_pairs]
        
        # Calculate Mongolian purity
        all_text = ' '.join([f"{p['prompt']} {p['chosen']} {p['rejected']}" for p in grpo_pairs])
        mongolian_chars = len(re.findall(r'[–ê-–Ø”®“Æ–∞-—è”©“Ø]', all_text))
        total_chars = len(re.findall(r'[–ê-–Ø”®“Æ–∞-—è”©“ØA-Za-z]', all_text))
        purity = (mongolian_chars / total_chars * 100) if total_chars > 0 else 0
        
        # Display summary
        print("\\nüìä GRPO DATASET GENERATION REPORT")
        print("=" * 50)
        print(f"Generation Results:")
        print(f"  Total prompts generated: {len(question_pairs)}")
        print(f"  Valid pairs: {len(grpo_pairs)}")
        print(f"  Success rate: 100.0%")
        print()
        print(f"Quality Metrics:")
        print(f"  Average prompt length: {sum(prompt_lengths)/len(prompt_lengths):.1f} words")
        print(f"  Average chosen length: {sum(chosen_lengths)/len(chosen_lengths):.1f} words")
        print(f"  Average rejected length: {sum(rejected_lengths)/len(rejected_lengths):.1f} words")
        print(f"  Dataset purity: {purity:.1f}% Mongolian")
        print()
        print(f"Status: ‚úÖ SUCCESS")
        print(f"‚úÖ Ready for GRPO fine-tuning")
        print()
        print("üîß To use the real GRPO builder:")
        print("1. Set your OpenAI API key: export OPENAI_API_KEY='your-key'")
        print("2. Run: python scripts/build_grpo_dataset.py")
        
        return output_file

def main():
    """Run demo GRPO dataset generation."""
    builder = DemoGRPOBuilder()
    
    # Use existing dataset
    source_file = Path("data/mgl_history_labeled.jsonl")
    output_file = Path("data/demo_grpo_dataset.jsonl")
    
    if not source_file.exists():
        print(f"‚ùå Source file not found: {source_file}")
        print("Please ensure you have Mongolian historical data available.")
        return 1
    
    try:
        result_file = builder.build_demo_grpo_dataset(source_file, output_file, pairs_count=8)
        print(f"\\nüéâ Demo completed! Check the results in: {result_file}")
        return 0
    except Exception as e:
        print(f"‚ùå Demo failed: {e}")
        return 1

if __name__ == "__main__":
    exit(main())