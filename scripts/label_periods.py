#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import re
import os
from collections import defaultdict, Counter

def load_merged_dataset(file_path):
    """Load the merged dataset from JSONL file"""
    print(f"üìñ Loading merged dataset: {file_path}")
    
    if not os.path.exists(file_path):
        print(f"‚ùå File not found: {file_path}")
        return []
    
    records = []
    error_count = 0
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                
                try:
                    record = json.loads(line)
                    records.append(record)
                except json.JSONDecodeError as e:
                    error_count += 1
                    if error_count <= 3:
                        print(f"‚ö†Ô∏è  JSON decode error on line {line_num}: {str(e)}")
        
        if error_count > 3:
            print(f"‚ö†Ô∏è  ... and {error_count - 3} more JSON errors")
        
        print(f"‚úÖ Loaded {len(records)} records")
        return records
    
    except Exception as e:
        print(f"‚ùå Error loading file: {str(e)}")
        return []

def define_period_patterns():
    """Define regex patterns for each historical period"""
    patterns = {
        '–≠—Ä—Ç–Ω–∏–π “Ø–µ': [
            # Ancient period keywords
            r'—Ö“Ø–Ω–Ω“Ø', r'–º–æ–¥—É–Ω', r'—à–∞–Ω—å—é–π', r'—Å—è–Ω—å–±–∏', r'–∂—É–∂–∞–Ω',
            r'—Ç“Ø—Ä—ç–≥\s+—É–ª—Å', r'—É–π–≥—É—Ä\s+—É–ª—Å', r'–∫–∏–¥–∞–Ω', r'–ª—è–æ',
            r'—ç—Ä—Ç–Ω–∏–π\s+—É–ª—Å', r'–±–∞–ª–∞—Ä\s+—ç—Ä—Ç', r'—á—É–ª—É—É–Ω\s+–∑—ç–≤—Å—ç–≥',
            r'—Ö“Ø—Ä—ç–ª\s+–∑—ç–≤—Å—ç–≥', r'—Ç”©–º—Ä–∏–π–Ω\s+“Ø–µ', r'–∞—Ä—Ö–µ–æ–ª–æ–≥–∏'
        ],
        'XIII –∑—É—É–Ω': [
            # 13th century - Mongol Empire
            r'—á–∏–Ω–≥–∏—Å\s*—Ö–∞–∞–Ω', r'—á–∏–Ω–≥–∏—Å—Ö–∞–∞–Ω', r'—Ç—ç–º“Ø–∂–∏–Ω', r'”©–≥”©–¥—ç–π',
            r'–º”©–Ω—Ö\s+—Ö–∞–∞–Ω', r'—Ö—É–±–∏–ª–∞–π', r'–∏—Ö\s+–º–æ–Ω–≥–æ–ª\s+—É–ª—Å',
            r'–º–æ–Ω–≥–æ–ª—ã–Ω\s+—ç–∑—ç–Ω—Ç\s+–≥“Ø—Ä—ç–Ω', r'—é–∞–Ω—å\s+—É–ª—Å', r'–Ω—É—É—Ü\s+—Ç–æ–≤—á–æ–æ',
            r'–º–æ–Ω–≥–æ–ª—ã–Ω\s+–Ω—É—É—Ü', r'xiii\s*–∑—É—É–Ω', r'13.*–∑—É—É–Ω'
        ],
        'XVII‚ÄìXIX –∑—É—É–Ω': [
            # 17th-19th century - Manchu period
            r'–º–∞–Ω–∂', r'—Ü–∏–Ω\s+—É–ª—Å', r'–º–∞–Ω—å—á–∂—É—Ä', r'–±–æ–≥–¥\s+—Ö–∞–∞–Ω',
            r'—Ç”©–≤”©–¥', r'–¥–∞–ª–∞–π\s+–ª–∞–º', r'–≥–∞–¥–∞–∞–¥\s+–º–æ–Ω–≥–æ–ª', r'”©–≤”©—Ä\s+–º–æ–Ω–≥–æ–ª',
            r'–∞–≤—Ç–æ–Ω–æ–º–∏', r'xvii.*–∑—É—É–Ω', r'xviii.*–∑—É—É–Ω', r'xix.*–∑—É—É–Ω',
            r'17.*–∑—É—É–Ω', r'18.*–∑—É—É–Ω', r'19.*–∑—É—É–Ω'
        ],
        'XX –∑—É—É–Ω': [
            # 20th century - Socialist period
            r'–±–Ω–º–∞—É', r'—Å“Ø—Ö–±–∞–∞—Ç–∞—Ä', r'—á–æ–π–±–∞–ª—Å–∞–Ω', r'–∞—Ä–¥—ã–Ω\s+—Ö—É–≤—å—Å–≥–∞–ª',
            r'—Å–æ—Ü–∏–∞–ª–∏–∑–º', r'–∫–æ–º–º—É–Ω–∏—Å—Ç', r'–∫–æ–º–∏–Ω—Ç–µ—Ä–Ω', r'–∑”©–≤–ª”©–ª—Ç',
            r'–ª–µ–Ω–∏–Ω', r'—Å—Ç–∞–ª–∏–Ω', r'xx\s*–∑—É—É–Ω', r'20.*–∑—É—É–Ω',
            r'1900', r'1910', r'1920', r'1930', r'1940', r'1950',
            r'1960', r'1970', r'1980', r'1990'
        ]
    }
    
    return patterns

def classify_historical_period(text, patterns):
    """Classify text into historical periods using regex patterns"""
    text_lower = text.lower()
    
    # Score each period based on pattern matches
    period_scores = {}
    period_matches = {}
    
    for period, period_patterns in patterns.items():
        matches = []
        score = 0
        
        for pattern in period_patterns:
            found_matches = re.findall(pattern, text_lower)
            if found_matches:
                matches.extend(found_matches)
                score += len(found_matches)
        
        period_scores[period] = score
        period_matches[period] = matches
    
    # Find the period with highest score
    if max(period_scores.values()) > 0:
        best_period = max(period_scores, key=period_scores.get)
        best_score = period_scores[best_period]
        best_matches = period_matches[best_period]
        
        # Calculate confidence based on number of matches
        if best_score >= 3:
            confidence = 1.0
        elif best_score == 2:
            confidence = 0.8
        else:
            confidence = 0.5
        
        return best_period, confidence, best_matches
    else:
        # Default to modern period if no matches
        return '–û—Ä—á–∏–Ω “Ø–µ', 0.3, []

def label_records(records):
    """Label all records with historical periods"""
    print(f"\nüè∑Ô∏è  Labeling historical periods...")
    
    patterns = define_period_patterns()
    labeled_records = []
    period_stats = defaultdict(int)
    confidence_stats = defaultdict(int)
    
    for i, record in enumerate(records, 1):
        text = record.get('text', '')
        title = record.get('title', '')
        
        # Combine title and text for classification
        full_text = f"{title} {text}"
        
        # Classify the period
        period, confidence, matches = classify_historical_period(full_text, patterns)
        
        # Create labeled record
        labeled_record = record.copy()
        labeled_record['period'] = period
        labeled_record['period_confidence'] = confidence
        labeled_record['period_matches'] = len(matches)
        
        labeled_records.append(labeled_record)
        
        # Update statistics
        period_stats[period] += 1
        confidence_range = f"{confidence:.1f}"
        confidence_stats[confidence_range] += 1
        
        # Print progress for first few and every 10th record
        if i <= 5 or i % 10 == 0:
            source = record.get('dataset_source', 'unknown')[:20]
            print(f"   [{i:2d}] {period:<15} (conf: {confidence:.1f}) - {source}")
    
    print(f"‚úÖ Labeled {len(labeled_records)} records")
    
    return labeled_records, period_stats, confidence_stats

def print_labeling_statistics(period_stats, confidence_stats, total_records):
    """Print detailed labeling statistics"""
    print(f"\nüìä Historical Period Distribution:")
    
    # Sort periods chronologically
    period_order = ['–≠—Ä—Ç–Ω–∏–π “Ø–µ', 'XIII –∑—É—É–Ω', 'XVII‚ÄìXIX –∑—É—É–Ω', 'XX –∑—É—É–Ω', '–û—Ä—á–∏–Ω “Ø–µ']
    
    for period in period_order:
        count = period_stats.get(period, 0)
        percentage = (count / total_records * 100) if total_records > 0 else 0
        print(f"   üìÖ {period:<15}: {count:2d} records ({percentage:4.1f}%)")
    
    print(f"\nüìà Confidence Distribution:")
    for conf_level in sorted(confidence_stats.keys(), reverse=True):
        count = confidence_stats[conf_level]
        percentage = (count / total_records * 100) if total_records > 0 else 0
        print(f"   üéØ Confidence {conf_level}: {count:2d} records ({percentage:4.1f}%)")
    
    # Calculate quality metrics
    high_conf_count = sum(count for conf, count in confidence_stats.items() 
                         if float(conf) >= 0.8)
    high_conf_pct = (high_conf_count / total_records * 100) if total_records > 0 else 0
    
    print(f"\nüéØ Quality Metrics:")
    print(f"   ‚úÖ High confidence (‚â•0.8): {high_conf_count} records ({high_conf_pct:.1f}%)")
    print(f"   üìä Average confidence: {sum(float(conf) * count for conf, count in confidence_stats.items()) / total_records:.2f}")

def save_labeled_dataset(records, output_path):
    """Save labeled dataset to JSONL file"""
    print(f"\nüíæ Saving labeled dataset...")
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            for record in records:
                json.dump(record, f, ensure_ascii=False)
                f.write('\n')
        
        print(f"‚úÖ Saved {len(records)} labeled records to {output_path}")
        return True
    
    except Exception as e:
        print(f"‚ùå Error saving file: {str(e)}")
        return False

def analyze_period_keywords(records, patterns):
    """Analyze which keywords were most effective for classification"""
    print(f"\nüîç Keyword Analysis:")
    
    keyword_usage = defaultdict(int)
    
    for record in records:
        text = record.get('text', '').lower()
        period = record.get('period', '')
        
        if period in patterns:
            for pattern in patterns[period]:
                if re.search(pattern, text):
                    keyword_usage[f"{period}:{pattern}"] += 1
    
    # Show top keywords for each period
    for period in patterns.keys():
        period_keywords = [(k.split(':')[1], v) for k, v in keyword_usage.items() 
                          if k.startswith(period)]
        period_keywords.sort(key=lambda x: x[1], reverse=True)
        
        if period_keywords:
            print(f"   üìÖ {period}:")
            for keyword, count in period_keywords[:3]:  # Top 3 keywords
                print(f"      üîë '{keyword}': {count} matches")

def print_labeling_summary(total_records, period_stats, output_path):
    """Print comprehensive labeling summary"""
    print(f"\n" + "="*60)
    print(f"üìä HISTORICAL PERIOD LABELING SUMMARY")
    print(f"="*60)
    
    print(f"üìà Processing Results:")
    print(f"   üìã Total records processed: {total_records}")
    print(f"   üè∑Ô∏è  Successfully labeled: {sum(period_stats.values())}")
    print(f"   üìÅ Output file: {output_path}")
    
    print(f"\nüéØ Labeling Quality:")
    if total_records > 0:
        # Find most and least common periods
        most_common = max(period_stats.items(), key=lambda x: x[1])
        least_common = min(period_stats.items(), key=lambda x: x[1])
        
        print(f"   üìä Most common period: {most_common[0]} ({most_common[1]} records)")
        print(f"   üìä Least common period: {least_common[0]} ({least_common[1]} records)")
    
    print(f"\nüéâ Labeling completed successfully!")
    print(f"üîó Ready for final dataset preparation")

def main():
    """Main period labeling function"""
    print("üè∑Ô∏è  Starting Historical Period Labeling...")
    print("="*60)
    
    try:
        # Define file paths
        input_file = 'data/mgl_history_merged.jsonl'
        output_file = 'data/mgl_history_labeled.jsonl'
        
        # Load merged dataset
        records = load_merged_dataset(input_file)
        if not records:
            print("‚ùå No records to process")
            return
        
        # Label records with historical periods
        labeled_records, period_stats, confidence_stats = label_records(records)
        
        # Print statistics
        print_labeling_statistics(period_stats, confidence_stats, len(labeled_records))
        
        # Analyze keyword effectiveness
        patterns = define_period_patterns()
        analyze_period_keywords(labeled_records, patterns)
        
        # Save labeled dataset
        if save_labeled_dataset(labeled_records, output_file):
            # Print summary
            print_labeling_summary(len(records), period_stats, output_file)
        else:
            print("‚ùå Failed to save labeled dataset")
    
    except Exception as e:
        print(f"‚ùå Error during labeling: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()